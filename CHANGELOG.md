# Changelog - MindCubes

TÃ¼m Ã¶nemli deÄŸiÅŸiklikler bu dosyada dokÃ¼mante edilir.

## [1.1.0] - 2025-11-16

### âœ¨ Yeni Ã–zellikler

#### HuggingFace Entegrasyonu
- **Otomatik Model Ä°ndirme:** Modeller HuggingFace Hub'dan otomatik indirilir ve cache'lenir
- **Quantization DesteÄŸi:** 4-bit ve 8-bit quantization ile bellek optimizasyonu
- **Gated Model DesteÄŸi:** Llama-2, Llama-3 gibi gated modellere HF_TOKEN ile eriÅŸim
- **Model Info API:** Model boyutu, parametre sayÄ±sÄ± gibi bilgilere eriÅŸim
- **Memory Management:** Model unload ve GPU memory temizleme fonksiyonlarÄ±

#### LocalModelProvider GÃ¼ncellemeleri
```python
LocalModelProvider(
    model_name="...",           # HuggingFace model ID
    cache_dir="...",            # Cache directory
    hf_token="...",             # HuggingFace token
    load_in_4bit=True,          # 4-bit quantization
    load_in_8bit=False,         # 8-bit quantization
    trust_remote_code=False     # Custom code support
)
```

#### Yeni Metodlar
- `get_model_size()` - Model boyut bilgisi
- `unload_model()` - Model'i memory'den kaldÄ±r
- `_get_model_info()` - HuggingFace model bilgileri

### ğŸ“š DokÃ¼mantasyon

#### Yeni DokÃ¼manlar
1. **GUIDELINES.md** - KapsamlÄ± geliÅŸtirme kurallarÄ±
   - Python, Node.js, React standartlarÄ±
   - OOP prensipleri
   - GÃ¼venlik kurallarÄ±
   - Test standartlarÄ±
   - Git workflow
   - Common pitfalls

2. **HUGGINGFACE_GUIDE.md** - HuggingFace kullanÄ±m rehberi
   - Model seÃ§imi
   - Quantization rehberi
   - Gated model eriÅŸimi
   - Ã–nerilen modeller
   - Performans ipuÃ§larÄ±
   - Sorun giderme

3. **examples/huggingface_examples.py** - 7 DetaylÄ± Ã–rnek
   - Basic usage
   - 4-bit quantization
   - Code generation
   - Agent integration
   - Gated models
   - Model comparison
   - Custom parameters

### ğŸ”§ Configuration

#### config.yaml GÃ¼ncellemeleri
```yaml
models:
  local:
    cache_dir: "./models/cache"
    device: "auto"
    load_in_4bit: false
    load_in_8bit: false
    trust_remote_code: false
  
  huggingface:
    recommended_models:
      code_generation: [...]
      chat: [...]
      small_models: [...]
```

### ğŸ“¦ Dependencies

#### Yeni Paketler
```txt
huggingface-hub>=0.19.0
sentencepiece>=0.1.99
protobuf>=3.20.0
```

### ğŸ¯ Ã–nerilen Modeller

#### Kod Ãœretimi
- `codellama/CodeLlama-7b-Instruct-hf` - 7B, en iyi kod modeli
- `bigcode/starcoder` - 15B, Ã§ok dilli
- `Salesforce/codegen-2B-mono` - 2B, kÃ¼Ã§Ã¼k GPU iÃ§in

#### Chat
- `microsoft/phi-2` - 2.7B, kÃ¼Ã§Ã¼k ama gÃ¼Ã§lÃ¼
- `TinyLlama/TinyLlama-1.1B-Chat-v1.0` - 1.1B, en hÄ±zlÄ±
- `mistralai/Mistral-7B-Instruct-v0.2` - 7B, yÃ¼ksek kalite

### ğŸ’¡ KullanÄ±m Ã–rnekleri

#### Temel KullanÄ±m
```python
from core import LocalModelProvider

provider = LocalModelProvider(
    model_name="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    load_in_4bit=True
)

response = await provider.generate("Python nedir?")
```

#### Agent ile
```python
from agents import CodeAgent

llm = LocalModelProvider(
    model_name="codellama/CodeLlama-7b-Instruct-hf",
    load_in_4bit=True
)

agent = CodeAgent(llm_provider=llm)
response = await agent.process("Fibonacci fonksiyonu yaz")
```

### ğŸ”’ GÃ¼venlik

- Environment variables for tokens
- .gitignore gÃ¼ncellendi
- Sensitive data kontrolleri

### ğŸ“ README GÃ¼ncellemeleri

- HuggingFace quick start eklendi
- Model indirme bilgisi eklendi
- Cache yÃ¶netimi aÃ§Ä±klandÄ±

---

## [1.0.0] - 2025-11-15

### ğŸ‰ Ä°lk SÃ¼rÃ¼m

#### Python AI Engine
- Base classes (Agent, Tool, LLM, Memory, Task, Orchestrator)
- 4 Specialized agents (Code, Data, Research, TaskPlanner)
- 5 Tools (WebSearch, CodeExecutor, FileManager, APICaller, DataProcessor)
- OpenAI & Anthropic provider support
- Model training infrastructure
- LoRA adapter support

#### Node.js Backend
- RESTful API
- MongoDB integration
- JWT authentication
- CRUD operations for Agents, Tasks, Models
- User management

#### React Frontend
- Dashboard
- Agent management
- Task monitoring
- Model registry
- Modern UI with Tailwind

#### Documentation
- README.md
- SETUP.md
- ARCHITECTURE.md
- ai-engine/README.md

---

## Planlanan Ã–zellikler

### [1.2.0] - Gelecek
- [ ] WebSocket support for real-time updates
- [ ] Advanced streaming for local models
- [ ] Multi-modal support (vision models)
- [ ] Fine-tuning UI
- [ ] Model marketplace

### [1.3.0] - Gelecek
- [ ] Distributed training
- [ ] Model versioning
- [ ] A/B testing for models
- [ ] Performance benchmarking

---

## NasÄ±l KatkÄ±da Bulunulur

1. GUIDELINES.md'yi okuyun
2. Feature branch oluÅŸturun
3. DeÄŸiÅŸikliklerinizi commit edin
4. Pull request aÃ§Ä±n

---

**Semantic Versioning:** MAJOR.MINOR.PATCH
- **MAJOR:** Breaking changes
- **MINOR:** Yeni Ã¶zellikler (backward compatible)
- **PATCH:** Bug fixes

